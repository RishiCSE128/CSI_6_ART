{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installing OpenCV\n",
    "\n",
    "## Check for the prerequisites\n",
    "Before you start, make sure the initial prerequisites are satisfied. Do the following check at the VSCode terminal (go to __Terminal__ tab then click on __new terminal__ or use the shortcut __CTRL + Shift + '__). \n",
    "\n",
    "1. Check for python : `python3 --version`\n",
    "2. Activate the environment : `source venv/bin/activate`\n",
    "3. pip is up-to-date : `python3 -m pip install --upgrade pip`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing packages\n",
    "\n",
    "* The `opencv-python` is the original python version for OpenCV which was originally developed using C++. \n",
    "* The `opencv-contrib-python` inherits the OpenCV base package, also it includes several contribution modules which are contributed by the OpenSource community.\n",
    "* OpenCV also installs `numpy` module for scientific computation as beneath the OpenCV main module all the numerical and linear algebraic operations are performed by numpy. \n",
    "* The `caer` package is an additional package that wraps several OpenCV functions for ease of use. \n",
    "\n",
    "`python3 -m pip install opencv-contrib-python caer`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1: Reading Images and Videos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First import the openCV module as cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Reading an Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following code, it must show up the __sample1.jpg__ image located at the __images__ folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_loc = 'images/sample1.jpg'  # defines the image location \n",
    "try:  # the exception handling prevents any accidental crash \n",
    "    img = cv.imread(image_loc)  # reads the image as a matrix \n",
    "    cv.imshow(winname='image', mat=img) # shows the image in a window \n",
    "    cv.waitKey(0)    # holds the image in the window until closed explicitly\n",
    "except:\n",
    "    print('Error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Output__ <br>\n",
    "![](figs/fig1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the image name to __sample2.jpg__ to see the change. You could also download another image from the Internet and place it into the same folder and try to show it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Reading videos\n",
    "### 1.2.1. Reading video from a file\n",
    "\n",
    "* A video is a sequence of images \n",
    "* to read a video, first create a __VideoCapture__ object\n",
    "* Read the object frame by frame using a while loop. A capture pointer starts from the first frame and iterate across the stream. \n",
    "* When done, release the capture pointer. \n",
    "* Destroy the window buffer.  \n",
    "\n",
    "Notice the code is encapsulated within a `try - except` block to avoid any unanticipated exception such as wrong file name, corrupted file etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_location = 'videos/sample_vid1.mp4'   # specify the video location\n",
    "try:\n",
    "    capture = cv.VideoCapture(video_location)   # reads the video into a capture object \n",
    "\n",
    "    while True:\n",
    "        isTrue, frame = capture.read()  # reads the video frame by frame, isTrue is boolean that stores the read status(boolean)\n",
    "        cv.imshow(winname='Sample Video', mat=frame) # show images frame by frame \n",
    "        if cv.waitKey(20) & 0xFF == ord('d'):        # stop the video is the key 'd' is pressed (you can change as per your choice)\n",
    "            break\n",
    "    capture.release()      # release the capture pointer\n",
    "    cv.destroyAllWindows() # clear all memory resources  \n",
    "except:\n",
    "    print('Error !!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Output__ <br>\n",
    "![](figs/fig2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the video file to __sample_vid2.mp4__ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.2. Reading a video from a live source \n",
    "Reading video from a live feed needs a simple adjustment. __Use the video location to 0__ the number represents the video input.\n",
    "* 0 is the default webcam \n",
    "* 1 if you have any additional camera and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_location = 0   # specify the video location  as webcam\n",
    "try:\n",
    "    capture = cv.VideoCapture(video_location)   # reads the video into a capture object \n",
    "\n",
    "    while True:\n",
    "        isTrue, frame = capture.read()  # reads the video frame by frame, isTrue is boolean that stores the read status(boolean)\n",
    "        cv.imshow(winname='Sample Video', mat=frame) # show images frame by frame \n",
    "        if cv.waitKey(20) & 0xFF == ord('d'):        # stop the video is the key 'd' is pressed (you can change as per your choice)\n",
    "            break\n",
    "    capture.release()      # release the capture pointer\n",
    "    cv.destroyAllWindows() # clear all memory resources  \n",
    "except:\n",
    "    print('Error !!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Output__ <br>\n",
    "\n",
    "![](figs/fig3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2: Scaling and Resizing \n",
    "\n",
    "* Large video files consume significant GPU resource to process\n",
    "* __Downscaling__ : Sometimes, a video frame is larger than the display screen size (watching 4K video in a 1080p screen). In such as case to reduce the unnecessary computation, it's a good idea to scale a video down to manageable size. \n",
    "* __Upscaling__ : On the contrary to _Downscaling_, the _Upscaling_ process increases each frame of a video and displays it (HD Ready feature, that takes a 1080p screen and displays a 4K version of it)\n",
    "* Its a best-practice to downscale a video for processing. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2.1. Custom Scaling "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step1 :__ We first start with creating a custom function called `scale_frame(frame, scale, side_by_side)` that takes a frame to be scaled and a scale factor (float) and returns a scaled frame by __Interpolation__. The __side_by_side__ parameter is unset by default, if it's set, the scaled and the original video will play side by side.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_frame(frame, scale):\n",
    "    # read the actual height and weight, scale it and store\n",
    "    height = int(frame.shape[0]*scale)\n",
    "    width = int(frame.shape[1]*scale)\n",
    "    \n",
    "    #return the scaled frame\n",
    "    return cv.resize(frame, (width, height), interpolation=cv.INTER_AREA) # performs rescaling by interpolation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 2:__ Create a read_video function that takes a video source(either a video file or a camera index), a scale factor as input and displays a scaled video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_video(source, scale, side_by_side=False):\n",
    "    try:\n",
    "        capture = cv.VideoCapture(source)\n",
    "        while True:\n",
    "            isTrue, frame = capture.read()\n",
    "            scaled_frame = scale_frame(frame, scale)  # calls the scale_frame function to scale each frame \n",
    "            \n",
    "            cv.imshow('scaled video', scaled_frame)\n",
    "            if side_by_side:\n",
    "                cv.imshow('original video', frame)\n",
    "            \n",
    "            if cv.waitKey(20) & 0XFF == ord('d'):\n",
    "                break\n",
    "        capture.release()\n",
    "    except:\n",
    "        print('error')\n",
    "    finally:\n",
    "        cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 3:__ Verify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_video(source=0, scale=2, side_by_side=True) # calling read_video with live feed, scaling 2X and playing with original by side."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Output__ <br>\n",
    "\n",
    "![](figs/fig4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Playing with various capture attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic Capture parameters:\n",
    "\n",
    "| id |  Parameter | meaning |\n",
    "|---|---|---|\n",
    "| 3 | CAP_PROP_FRAME_WIDTH | width |\n",
    "| 4 | CAP_PROP_FRAME_HEIGHT | Height |\n",
    "| 5 | CAP_PROP_FPS | FPS |\n",
    "| 6 | CAP_PROP_POS_MSEC | Current position of the capture pointer |\n",
    "| 7 | CAP_PROP_FRAME_COUNT | total number of frames in the video file|\n",
    "| 8 | CAP_PROP_BRIGHTNESS | It only works with a camera or webcam. Used to find out the brightness | \n",
    "| 9 | CAP_PROP_CONTRAST | This property also works with the camera or webcam only. Used to find out the contrast on images captured |\n",
    "| 10 | CAP_PROP_SATURATION | This is used to get the saturation of live frames capturing via cameras. This also doesn’t work on the video file.|\n",
    "|11 | CAP_PROP_HUE | This is for knowing the HUE value of the image. Only for cameras.|\n",
    "|12 | CAP_PROP_GAIN | This property is used to get the gain of the image. Wouldn’t work with the video file, simply return “0” if applied on a video file|\n",
    "|13| CAP_PROP_CONVERT_RGB | This property returns a Boolean value which indicates whether the images should be converted to RGB colorspace or not | \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1 Getting the params\n",
    "\n",
    "The following code will read the basic OpenCV parameter from a live video and shows it while streaming from the source. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "def show_details(capture):   # prints the basic attributes \n",
    "    clear_output(wait=True)  # clear the notebook cell after printing \n",
    "    print(f\"CAP_PROP_FRAME_WIDTH \\t: {capture.get(cv.CAP_PROP_FRAME_WIDTH)}\")\n",
    "    print(f\"CAP_PROP_FRAME_HEIGHT \\t: {capture.get(cv.CAP_PROP_FRAME_HEIGHT)}\")\n",
    "    print(f\"CAP_PROP_FPS        \\t: {capture.get(cv.CAP_PROP_FPS)}\")\n",
    "    print(f\"CAP_PROP_POS_MSEC   \\t: {capture.get(cv.CAP_PROP_POS_MSEC)}\")\n",
    "    print(f\"CAP_PROP_FRAME_COUNT \\t: {capture.get(cv.CAP_PROP_FRAME_COUNT)}\")\n",
    "    print(f\"CAP_PROP_BRIGHTNESS \\t: {capture.get(cv.CAP_PROP_BRIGHTNESS)}\")\n",
    "    print(f\"CAP_PROP_CONTRAST   \\t: {capture.get(cv.CAP_PROP_CONTRAST)}\")\n",
    "    print(f\"CAP_PROP_SATURATION \\t: {capture.get(cv.CAP_PROP_SATURATION)}\")\n",
    "    print(f\"CAP_PROP_HUE        \\t: {capture.get(cv.CAP_PROP_HUE)}\")\n",
    "    print(f\"CAP_PROP_GAIN       \\t: {capture.get(cv.CAP_PROP_GAIN)}\")\n",
    "    print(f\"CAP_PROP_CONVERT_RGB \\t: {capture.get(cv.CAP_PROP_CONVERT_RGB)}\")\n",
    "\n",
    "def show_video(source): \n",
    "    capture = cv.VideoCapture(source)\n",
    "    while True:\n",
    "        isTrue, frame = capture.read()\n",
    "        show_details(capture)   # calling the capture details \n",
    "        cv.imshow('Window', frame)\n",
    "        if cv.waitKey(20) & 0xFF == ord('d'): # press 'd' to exit\n",
    "            break\n",
    "    capture.release()\n",
    "    cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CAP_PROP_FRAME_WIDTH \t: 640.0\n",
      "CAP_PROP_FRAME_HEIGHT \t: 480.0\n",
      "CAP_PROP_FPS        \t: 30.0\n",
      "CAP_PROP_POS_MSEC   \t: 736991915.211\n",
      "CAP_PROP_FRAME_COUNT \t: -1.0\n",
      "CAP_PROP_BRIGHTNESS \t: 0.0\n",
      "CAP_PROP_CONTRAST   \t: 0.0\n",
      "CAP_PROP_SATURATION \t: 64.0\n",
      "CAP_PROP_HUE        \t: 0.0\n",
      "CAP_PROP_GAIN       \t: 1.0\n",
      "CAP_PROP_CONVERT_RGB \t: 1.0\n"
     ]
    }
   ],
   "source": [
    "show_video(source=0) # calling the live capture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2. Setting the params "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## set params\n",
    "alter_param = {\n",
    "    'width' : 640, \n",
    "    'height': 480, \n",
    "    'fps' : 30, \n",
    "    'brightness' : 50,\n",
    "    'contrast' : 10,\n",
    "    'saturation' : 100,\n",
    "    'hue': 0,\n",
    "    'gain' : 1,\n",
    "    'rgb' : 1 \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sourcecode\n",
    "from IPython.display import clear_output\n",
    "\n",
    "def show_details(capture):   # prints the basic attributes \n",
    "    clear_output(wait=True)  # clear the notebook cell after printing \n",
    "    print(f\"CAP_PROP_FRAME_WIDTH \\t: {capture.get(cv.CAP_PROP_FRAME_WIDTH)}\")\n",
    "    print(f\"CAP_PROP_FRAME_HEIGHT \\t: {capture.get(cv.CAP_PROP_FRAME_HEIGHT)}\")\n",
    "    print(f\"CAP_PROP_FPS        \\t: {capture.get(cv.CAP_PROP_FPS)}\")\n",
    "    print(f\"CAP_PROP_POS_MSEC   \\t: {capture.get(cv.CAP_PROP_POS_MSEC)}\")\n",
    "    print(f\"CAP_PROP_FRAME_COUNT \\t: {capture.get(cv.CAP_PROP_FRAME_COUNT)}\")\n",
    "    print(f\"CAP_PROP_BRIGHTNESS \\t: {capture.get(cv.CAP_PROP_BRIGHTNESS)}\")\n",
    "    print(f\"CAP_PROP_CONTRAST   \\t: {capture.get(cv.CAP_PROP_CONTRAST)}\")\n",
    "    print(f\"CAP_PROP_SATURATION \\t: {capture.get(cv.CAP_PROP_SATURATION)}\")\n",
    "    print(f\"CAP_PROP_HUE        \\t: {capture.get(cv.CAP_PROP_HUE)}\")\n",
    "    print(f\"CAP_PROP_GAIN       \\t: {capture.get(cv.CAP_PROP_GAIN)}\")\n",
    "    print(f\"CAP_PROP_CONVERT_RGB \\t: {capture.get(cv.CAP_PROP_CONVERT_RGB)}\")\n",
    "\n",
    "def alter_params(capture, alter_param):   # alters the parameters \n",
    "    capture.set(cv.CAP_PROP_FRAME_WIDTH, alter_param['width'])\n",
    "    capture.set(cv.CAP_PROP_FRAME_HEIGHT, alter_param['height'])\n",
    "    capture.set(cv.CAP_PROP_FPS, alter_param['fps'])\n",
    "    capture.set(cv.CAP_PROP_BRIGHTNESS, alter_param['brightness'])\n",
    "    capture.set(cv.CAP_PROP_CONTRAST, alter_param['contrast'])\n",
    "    capture.set(cv.CAP_PROP_SATURATION, alter_param['saturation'])\n",
    "    capture.set(cv.CAP_PROP_HUE, alter_param['hue'])\n",
    "    capture.set(cv.CAP_PROP_GAIN, alter_param['gain'])\n",
    "    capture.set(cv.CAP_PROP_CONVERT_RGB, alter_param['rgb'])\n",
    "    return capture\n",
    "\n",
    "def show_video(source):    # renders the video stream \n",
    "    print('Preparing capture... ')\n",
    "    try:\n",
    "        capture = cv.VideoCapture(source)\n",
    "        capture = alter_params(capture, alter_param) # calling to alter the params\n",
    "        print('Displaying... ')\n",
    "        while True:\n",
    "            isTrue, frame = capture.read()\n",
    "            show_details(capture)   # calling the capture details \n",
    "            cv.imshow('Window', frame)\n",
    "            if cv.waitKey(20) & 0xFF == ord('d'): # press 'd' to exit\n",
    "                break\n",
    "        capture.release()\n",
    "    except:\n",
    "        print('Error')\n",
    "    finally:\n",
    "        cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CAP_PROP_FRAME_WIDTH \t: 640.0\n",
      "CAP_PROP_FRAME_HEIGHT \t: 480.0\n",
      "CAP_PROP_FPS        \t: 30.0\n",
      "CAP_PROP_POS_MSEC   \t: 744583848.9555\n",
      "CAP_PROP_FRAME_COUNT \t: -1.0\n",
      "CAP_PROP_BRIGHTNESS \t: 0.0\n",
      "CAP_PROP_CONTRAST   \t: 0.0\n",
      "CAP_PROP_SATURATION \t: 64.0\n",
      "CAP_PROP_HUE        \t: 0.0\n",
      "CAP_PROP_GAIN       \t: 1.0\n",
      "CAP_PROP_CONVERT_RGB \t: 1.0\n"
     ]
    }
   ],
   "source": [
    "show_video(source=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__output__ <br>\n",
    "\n",
    "![](figs/fig5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3: Drawing shapes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first practice, we're going to see how to create a blank (dummy) image using __numpy__ and then draw basic shapes on top of it. Then we'll do the same on a real image and finally on a video.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Drawing on a blank image "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Creating a black image \n",
    "\n",
    "As digital images are read as a $m\\times n$ matrix, we do a reverse engineering here. We'll first create a blank matrix and present it as an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np   # library to to matrix operations\n",
    "import cv2 as cv\n",
    "\n",
    "image_size = (640,480)  # define the image size\n",
    "\n",
    "blank_matrix = np.zeros(image_size, dtype='uint8') # create a 8-bit unsigned integer matrix \n",
    "try:\n",
    "    cv.imshow(winname='blank_image', mat=blank_matrix)\n",
    "    cv.waitKey(0)\n",
    "except:\n",
    "    print('Error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Output__\n",
    "\n",
    "![](figs/fig6.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create a color image, we need a 3D matrix. the first two dimension are the height and width and the third one is the color depth.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = (640,480,3)  # define the image size with color depth of 3 channel\n",
    "\n",
    "blank_matrix = np.zeros(image_size, dtype='uint8') # create a 8-bit unsigned integer matrix \n",
    "blank_matrix[:] = 0,255,0   # the values are in R,G,B format (change it to get more colors)\n",
    "try:\n",
    "    cv.imshow(winname='blank_image', mat=blank_matrix)\n",
    "    cv.waitKey(0)\n",
    "except:\n",
    "    print('Error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Output__\n",
    "\n",
    "![](figs/fig7.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also color the image partially, by selecting specific row and column range "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = (640,480,3)  # define the image size with color depth of 3 channel\n",
    "\n",
    "height, width, depth = image_size\n",
    "\n",
    "blank_matrix = np.zeros(image_size, dtype='uint8') # create a 8-bit unsigned integer matrix \n",
    "\n",
    "# coloring image segments\n",
    "blank_matrix[0 : height//2 , 0 : width//2] = 255,0,0   # top left quarter \n",
    "blank_matrix[0 : height//2 , width//2 : width] = 0,255,0   # top right quarter \n",
    "blank_matrix[height//2 : height , 0 : width//2] = 0,0,255   # bottom left quarter\n",
    "blank_matrix[height//2 : height , width//2 : width] = 255,0,255   # bottom left quarter  \n",
    "\n",
    "try:\n",
    "    cv.imshow(winname='blank_image', mat=blank_matrix)\n",
    "    cv.waitKey(0)\n",
    "except:\n",
    "    print('Error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Output__\n",
    "\n",
    "![](figs/fig8.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Creating basic shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = (600,800,3)  # define the image size\n",
    "\n",
    "blank_matrix = np.zeros(image_size, dtype='uint8') # create a 8-bit unsigned integer matrix \n",
    "\n",
    "# adding text \n",
    "cv.putText(img=blank_matrix, \n",
    "           org=(300, 50),         # origin point \n",
    "           text='Test Shapes',    # text to print \n",
    "           color=(255,255,0),     # Text color\n",
    "           fontFace=cv.FONT_HERSHEY_PLAIN, # font to use\n",
    "           fontScale=2)           # font size      \n",
    "\n",
    "#drawing a rectangle\n",
    "cv.rectangle(img=blank_matrix,     # where to draw?\n",
    "            pt1=(100,100),         # top-left \n",
    "            pt2=(300,300),         # bottom-right\n",
    "            color=(255,0,0),       # stroke-color\n",
    "            thickness=2)           # stroke-width\n",
    "\n",
    "#drawing a rectangle with filled color\n",
    "cv.rectangle(img=blank_matrix,     \n",
    "            pt1=(200,200),         \n",
    "            pt2=(400,400),       \n",
    "            color=(255,0,0),       \n",
    "            thickness=-1)   # stroke-width (use cv.FILLED or -1 to fill)\n",
    "\n",
    "#drawing a circle\n",
    "cv.circle(img=blank_matrix, \n",
    "          center=(400,400),        # cordinate of the center \n",
    "          radius=200,              # radius \n",
    "          color=(0,255,0),         \n",
    "          thickness=2)\n",
    "\n",
    "#drawing a line \n",
    "cv.line(img=blank_matrix,\n",
    "        pt1=(100,100),       # start coordinate \n",
    "        pt2=(400,400),       # end coordinate  \n",
    "        color=(0,0,255), \n",
    "        thickness=2)\n",
    "\n",
    "try:\n",
    "    cv.imshow(winname='blank_image', mat=blank_matrix)\n",
    "    cv.waitKey(0)\n",
    "except:\n",
    "    print('Error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](figs/shapes_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task \n",
    "Write a function to draw the figure below <br>\n",
    "![](figs/shapes.png) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4: Basic Image processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. Converting into Greyscale "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = 'images/sample1.jpg'\n",
    "\n",
    "try:\n",
    "    image = cv.imread(image_path)   # loads the image \n",
    "    image_grey = cv.cvtColor(image, cv.COLOR_BGR2GRAY) #converting into grey \n",
    "\n",
    "    cv.imshow(winname='Original image', mat=image)  # shows original\n",
    "    cv.imshow(winname='Greyscale image', mat=image_grey) # shows greyscale \n",
    "    cv.waitKey(0)\n",
    "except:\n",
    "    print('Error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](figs/fig9.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2. Blurring \n",
    "\n",
    "The blurring effect is done by convolving a $2\\times 2$ window called _Kernel_ over sliding over the image and replacing the member pixels using the average value. The kernel size should be an odd number. Higher the number, higher the blur. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = 'images/sample1.jpg'\n",
    "try:\n",
    "    image = cv.imread(image_path)   # loads the image \n",
    "\n",
    "    kernel_size=(5,5)  # 2x2 kernel size, use an odd number\n",
    "    image_blured = cv.GaussianBlur(src=image, ksize=kernel_size, sigmaX=cv.BORDER_DEFAULT) #converting into grey \n",
    "\n",
    "    cv.imshow(winname='Original image', mat=image)  # shows original\n",
    "    cv.imshow(winname='Blurred image', mat=image_blured) # shows greyscale \n",
    "    cv.waitKey(0)\n",
    "except:\n",
    "    print('Error')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](figs/fig10.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try increasing the kernel size, and see the effect... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.3. Edge Detection \n",
    "For complex images, it's recommended to blur the image first to detect fewer edges. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = 'images/sample1.jpg'\n",
    "try:\n",
    "    image = cv.imread(image_path)   # loads the image \n",
    "\n",
    "    # alther the thresholds to control edges \n",
    "    low_lim = 125\n",
    "    up_lim = 175\n",
    "    image_edges = cv.Canny(image=image, threshold1=low_lim, threshold2=up_lim) # edge detection \n",
    "\n",
    "    cv.imshow(winname='Original image', mat=image)  # shows original\n",
    "    cv.imshow(winname='Image Edges', mat=image_edges) # shows greyscale \n",
    "    cv.waitKey(0)\n",
    "except:\n",
    "    print('Error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](figs/fig11.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4. Scaling \n",
    "\n",
    "For scaling or resizing and image, the image needs to be interpolated to recalculate the pixel values.\n",
    "* While down-scaling, the image use `cv.INTER_AREA` method (which is the default one).\n",
    "* While up-scaling, use either `cv.INTER_LINEAR` or `cv.INTER_CUBIC` (cubic is more computationally intensive but better)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = 'images/sample1.jpg'\n",
    "try:\n",
    "    image = cv.imread(image_path)   # loads the image \n",
    "\n",
    "    # alther the thresholds to control edges\n",
    "    original_res = image.shape \n",
    "    scale = 2\n",
    "    target_res = (scale*original_res[1], scale*original_res[0]) # calculated target resolution by scaling \n",
    "    image_scaled = cv.resize(image, target_res, interpolation=cv.INTER_AREA) # scaling \n",
    "\n",
    "    cv.imshow(winname=f'Original image ({original_res[0]}X{original_res[1]})', mat=image)  # shows original\n",
    "    cv.imshow(winname=f'Scaled image ({target_res})', mat=image_scaled) # shows scaled  \n",
    "    cv.waitKey(0)\n",
    "except:\n",
    "    print('Error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](figs/fig12.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 5 : Color Spaces\n",
    "\n",
    "OpenCV reads an color image in the BGR format by default. Whereas, the computer screen renders an image in RGB. In this example we're going to use _matplotlib_ to show images instead of the windows converting the images into different color schemes. \n",
    "1. RGB\n",
    "2. HSV\n",
    "3. LAB "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = 'images/sample1.jpg'\n",
    "\n",
    "try:\n",
    "    image_bgr = cv.imread(image_path)    # default BGR \n",
    "\n",
    "    image_bgr = cv.resize(image_bgr, (1920//2, 1080//2),cv.INTER_AREA) ## resing to fit 4 pics in screen \n",
    "\n",
    "    image_rgb = cv.cvtColor(image_bgr, cv.COLOR_BGR2RGB) # BGR --> RGB\n",
    "    image_hsv = cv.cvtColor(image_bgr, cv.COLOR_BGR2HSV) # BGR --> HSV  \n",
    "    image_lab = cv.cvtColor(image_bgr, cv.COLOR_BGR2LAB) # BGR --> HSV  \n",
    "\n",
    "    cv.imshow('original', image_bgr)\n",
    "    cv.imshow('HSV', image_hsv)\n",
    "    cv.imshow('RGB', image_rgb)\n",
    "    cv.imshow('LAB', image_lab) \n",
    "\n",
    "    cv.waitKey(0)\n",
    "except:\n",
    "    print('Error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](figs/fig13.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 6 : Color Channels \n",
    "\n",
    "When splitting an color image the dimension of the resulting images per channel changes as the 3rd dimension gets lost. Therefore, when showing them as it is, it appears to be a Greyscale image with the channeled colored washed out. To add the third dimension the process is given below....\n",
    "1. create a blank image with same resolution \n",
    "2. Merge individual channel with other two channels as blank\n",
    "    1. Blue  = (blue_channel , blank , blank )\n",
    "    2. Green = (blank, green_channel , blank  )\n",
    "    3. Red = ( blank , blank , red_channel )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "image_path = 'images/sample1.jpg'\n",
    "\n",
    "try:\n",
    "    image = cv.imread(image_path)    # default BGR \n",
    "\n",
    "    image = cv.resize(image, (1920//2, 1080//2), interpolation=cv.INTER_AREA)\n",
    "    image_b,image_g,image_r = cv.split(image)  # channel split\n",
    "\n",
    "    # merging \n",
    "    blank_image = np.zeros(image.shape[:2], dtype='uint8')\n",
    "    image_b = cv.merge([image_b, blank_image, blank_image])\n",
    "    image_g = cv.merge([blank_image, image_g, blank_image])\n",
    "    image_r = cv.merge([blank_image, blank_image, image_r])\n",
    "\n",
    "\n",
    "    cv.imshow('original', image)\n",
    "    cv.imshow('Blue', image_b)\n",
    "    cv.imshow('Green', image_g)\n",
    "    cv.imshow('Red', image_r) \n",
    "\n",
    "    cv.waitKey(0)\n",
    "except:\n",
    "    print('Error...')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](figs/fig14.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 7 : Histogram "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'matplotlib' has no attribute 'get_data_path'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\sapta\\Documents\\GitHub\\CSI_6_ART\\Tut_1\\OpenCV.ipynb Cell 75'\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/sapta/Documents/GitHub/CSI_6_ART/Tut_1/OpenCV.ipynb#ch0000095?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/sapta/Documents/GitHub/CSI_6_ART/Tut_1/OpenCV.ipynb#ch0000095?line=2'>3</a>\u001b[0m image_path \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mimages/sample1.jpg\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/sapta/Documents/GitHub/CSI_6_ART/Tut_1/OpenCV.ipynb#ch0000095?line=4'>5</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\sapta\\Documents\\GitHub\\CSI_6_ART\\venv\\lib\\site-packages\\matplotlib\\__init__.py:877\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/sapta/Documents/GitHub/CSI_6_ART/venv/lib/site-packages/matplotlib/__init__.py?line=869'>870</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m config\n\u001b[0;32m    <a href='file:///c%3A/Users/sapta/Documents/GitHub/CSI_6_ART/venv/lib/site-packages/matplotlib/__init__.py?line=872'>873</a>\u001b[0m \u001b[39m# When constructing the global instances, we need to perform certain updates\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/sapta/Documents/GitHub/CSI_6_ART/venv/lib/site-packages/matplotlib/__init__.py?line=873'>874</a>\u001b[0m \u001b[39m# by explicitly calling the superclass (dict.update, dict.items) to avoid\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/sapta/Documents/GitHub/CSI_6_ART/venv/lib/site-packages/matplotlib/__init__.py?line=874'>875</a>\u001b[0m \u001b[39m# triggering resolution of _auto_backend_sentinel.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/sapta/Documents/GitHub/CSI_6_ART/venv/lib/site-packages/matplotlib/__init__.py?line=875'>876</a>\u001b[0m rcParamsDefault \u001b[39m=\u001b[39m _rc_params_in_file(\n\u001b[1;32m--> <a href='file:///c%3A/Users/sapta/Documents/GitHub/CSI_6_ART/venv/lib/site-packages/matplotlib/__init__.py?line=876'>877</a>\u001b[0m     cbook\u001b[39m.\u001b[39;49m_get_data_path(\u001b[39m\"\u001b[39;49m\u001b[39mmatplotlibrc\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m    <a href='file:///c%3A/Users/sapta/Documents/GitHub/CSI_6_ART/venv/lib/site-packages/matplotlib/__init__.py?line=877'>878</a>\u001b[0m     \u001b[39m# Strip leading comment.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/sapta/Documents/GitHub/CSI_6_ART/venv/lib/site-packages/matplotlib/__init__.py?line=878'>879</a>\u001b[0m     transform\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m line: line[\u001b[39m1\u001b[39m:] \u001b[39mif\u001b[39;00m line\u001b[39m.\u001b[39mstartswith(\u001b[39m\"\u001b[39m\u001b[39m#\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39melse\u001b[39;00m line,\n\u001b[0;32m    <a href='file:///c%3A/Users/sapta/Documents/GitHub/CSI_6_ART/venv/lib/site-packages/matplotlib/__init__.py?line=879'>880</a>\u001b[0m     fail_on_error\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m    <a href='file:///c%3A/Users/sapta/Documents/GitHub/CSI_6_ART/venv/lib/site-packages/matplotlib/__init__.py?line=880'>881</a>\u001b[0m \u001b[39mdict\u001b[39m\u001b[39m.\u001b[39mupdate(rcParamsDefault, rcsetup\u001b[39m.\u001b[39m_hardcoded_defaults)\n\u001b[0;32m    <a href='file:///c%3A/Users/sapta/Documents/GitHub/CSI_6_ART/venv/lib/site-packages/matplotlib/__init__.py?line=881'>882</a>\u001b[0m \u001b[39m# Normally, the default matplotlibrc file contains *no* entry for backend (the\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/sapta/Documents/GitHub/CSI_6_ART/venv/lib/site-packages/matplotlib/__init__.py?line=882'>883</a>\u001b[0m \u001b[39m# corresponding line starts with ##, not #; we fill on _auto_backend_sentinel\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/sapta/Documents/GitHub/CSI_6_ART/venv/lib/site-packages/matplotlib/__init__.py?line=883'>884</a>\u001b[0m \u001b[39m# in that case.  However, packagers can set a different default backend\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/sapta/Documents/GitHub/CSI_6_ART/venv/lib/site-packages/matplotlib/__init__.py?line=884'>885</a>\u001b[0m \u001b[39m# (resulting in a normal `#backend: foo` line) in which case we should *not*\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/sapta/Documents/GitHub/CSI_6_ART/venv/lib/site-packages/matplotlib/__init__.py?line=885'>886</a>\u001b[0m \u001b[39m# fill in _auto_backend_sentinel.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\matplotlib\\cbook\\__init__.py:518\u001b[0m, in \u001b[0;36m_get_data_path\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m    <a href='file:///~/AppData/Roaming/Python/Python39/site-packages/matplotlib/cbook/__init__.py?line=511'>512</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_data_path\u001b[39m(\u001b[39m*\u001b[39margs):\n\u001b[0;32m    <a href='file:///~/AppData/Roaming/Python/Python39/site-packages/matplotlib/cbook/__init__.py?line=512'>513</a>\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    <a href='file:///~/AppData/Roaming/Python/Python39/site-packages/matplotlib/cbook/__init__.py?line=513'>514</a>\u001b[0m \u001b[39m    Return the `pathlib.Path` to a resource file provided by Matplotlib.\u001b[39;00m\n\u001b[0;32m    <a href='file:///~/AppData/Roaming/Python/Python39/site-packages/matplotlib/cbook/__init__.py?line=514'>515</a>\u001b[0m \n\u001b[0;32m    <a href='file:///~/AppData/Roaming/Python/Python39/site-packages/matplotlib/cbook/__init__.py?line=515'>516</a>\u001b[0m \u001b[39m    ``*args`` specify a path relative to the base data path.\u001b[39;00m\n\u001b[0;32m    <a href='file:///~/AppData/Roaming/Python/Python39/site-packages/matplotlib/cbook/__init__.py?line=516'>517</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> <a href='file:///~/AppData/Roaming/Python/Python39/site-packages/matplotlib/cbook/__init__.py?line=517'>518</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m Path(matplotlib\u001b[39m.\u001b[39;49mget_data_path(), \u001b[39m*\u001b[39margs)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'matplotlib' has no attribute 'get_data_path'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "image_path = 'images/sample1.jpg'\n",
    "\n",
    "try:\n",
    "    image_bgr = cv.imread(image_path)    # default BGR \n",
    "\n",
    "    image_bgr = cv.resize(image_bgr, (1920//2, 1080//2),cv.INTER_AREA) ## resing to fit 4 pics in screen \n",
    "\n",
    "    image_rgb = cv.cvtColor(image_bgr, cv.COLOR_BGR2GRAY)# BGP --> Grey \n",
    "    image_rgb = cv.cvtColor(image_bgr, cv.COLOR_BGR2RGB) # BGR --> RGB\n",
    "    image_hsv = cv.cvtColor(image_bgr, cv.COLOR_BGR2HSV) # BGR --> HSV  \n",
    "    image_lab = cv.cvtColor(image_bgr, cv.COLOR_BGR2LAB) # BGR --> HSV  \n",
    "\n",
    "    gray_hist = cv.calcHist(images=[image_grey], channels=[0], mask=None, histSize=[256], ranges=[0,256])\n",
    "    plt.plot(gray_hist)\n",
    "except:\n",
    "    print('Error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0f3bb31c5957d94de20b221c63d8001d2e67169bbb608e5802db09df6465f3be"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
