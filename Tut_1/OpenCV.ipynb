{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installing OpenCV\n",
    "\n",
    "## Check for the prerequisites\n",
    "Before you start, make sure the initial prerequisites are satisfied. Do the following check at the VSCode terminal (go to __Terminal__ tab then click on __new terminal__ or use the shortcut __CTRL + Shift + '__). \n",
    "\n",
    "1. Check for python : `python3 --version`\n",
    "2. Activate the environment : `source venv/bin/activate`\n",
    "3. pip is up-to-date : `python3 -m pip install --upgrade pip`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing packages\n",
    "\n",
    "* The `opencv-python` is the original python version for OpenCV which was originally developed using C++. \n",
    "* The `opencv-contrib-python` inherits the OpenCV base package, also it includes several contribution modules which are contributed by the OpenSource community.\n",
    "* OpenCV also installs `numpy` module for scientific computation as beneath the OpenCV main module all the numerical and linear algebraic operations are performed by numpy. \n",
    "* The `caer` package is an additional package that wraps several OpenCV functions for ease of use. \n",
    "\n",
    "`python3 -m pip install opencv-contrib-python caer`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1: Reading Images and Videos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First import the openCV module as cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Reading an Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following code, it must show up the __sample1.jpg__ image located at the __images__ folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_loc = 'images/sample1.jpg'  # defines the image location \n",
    "try:  # the exception handling prevents any accidental crash \n",
    "    img = cv.imread(image_loc)  # reads the image as a matrix \n",
    "    cv.imshow(winname='image', mat=img) # shows the image in a window \n",
    "    cv.waitKey(0)    # holds the image in the window until closed explicitly\n",
    "except:\n",
    "    print('Error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Output__ <br>\n",
    "![](figs/fig1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the image name to __sample2.jpg__ to see the change. You could also download another image from the Internet and place it into the same folder and try to show it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Reading videos\n",
    "### 1.2.1. Reading video from a file\n",
    "\n",
    "* A video is a sequence of images \n",
    "* to read a video, first create a __VideoCapture__ object\n",
    "* Read the object frame by frame using a while loop. A capture pointer starts from the first frame and iterate across the stream. \n",
    "* When done, release the capture pointer. \n",
    "* Destroy the window buffer.  \n",
    "\n",
    "Notice the code is encapsulated within a `try - except` block to avoid any unanticipated exception such as wrong file name, corrupted file etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_location = 'videos/sample_vid1.mp4'   # specify the video location\n",
    "try:\n",
    "    capture = cv.VideoCapture(video_location)   # reads the video into a capture object \n",
    "\n",
    "    while True:\n",
    "        isTrue, frame = capture.read()  # reads the video frame by frame, isTrue is boolean that stores the read status(boolean)\n",
    "        cv.imshow(winname='Sample Video', mat=frame) # show images frame by frame \n",
    "        if cv.waitKey(20) & 0xFF == ord('d'):        # stop the video is the key 'd' is pressed (you can change as per your choice)\n",
    "            break\n",
    "    capture.release()      # release the capture pointer\n",
    "    cv.destroyAllWindows() # clear all memory resources  \n",
    "except:\n",
    "    print('Error !!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Output__ <br>\n",
    "![](figs/fig2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the video file to __sample_vid2.mp4__ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.2. Reading a video from a live source \n",
    "Reading video from a live feed needs a simple adjustment. __Use the video location to 0__ the number represents the video input.\n",
    "* 0 is the default webcam \n",
    "* 1 if you have any additional camera and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_location = 0   # specify the video location  as webcam\n",
    "try:\n",
    "    capture = cv.VideoCapture(video_location)   # reads the video into a capture object \n",
    "\n",
    "    while True:\n",
    "        isTrue, frame = capture.read()  # reads the video frame by frame, isTrue is boolean that stores the read status(boolean)\n",
    "        cv.imshow(winname='Sample Video', mat=frame) # show images frame by frame \n",
    "        if cv.waitKey(20) & 0xFF == ord('d'):        # stop the video is the key 'd' is pressed (you can change as per your choice)\n",
    "            break\n",
    "    capture.release()      # release the capture pointer\n",
    "    cv.destroyAllWindows() # clear all memory resources  \n",
    "except:\n",
    "    print('Error !!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Output__ <br>\n",
    "\n",
    "![](figs/fig3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2: Scaling and Resizing \n",
    "\n",
    "* Large video files consume significant GPU resource to process\n",
    "* __Downscaling__ : Sometimes, a video frame is larger than the display screen size (watching 4K video in a 1080p screen). In such as case to reduce the unnecessary computation, it's a good idea to scale a video down to manageable size. \n",
    "* __Upscaling__ : On the contrary to _Downscaling_, the _Upscaling_ process increases each frame of a video and displays it (HD Ready feature, that takes a 1080p screen and displays a 4K version of it)\n",
    "* Its a best-practice to downscale a video for processing. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2.1. Custom Scaling "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step1 :__ We first start with creating a custom function called `scale_frame(frame, scale, side_by_side)` that takes a frame to be scaled and a scale factor (float) and returns a scaled frame by __Interpolation__. The __side_by_side__ parameter is unset by default, if it's set, the scaled and the original video will play side by side.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_frame(frame, scale):\n",
    "    # read the actual height and weight, scale it and store\n",
    "    height = int(frame.shape[0]*scale)\n",
    "    width = int(frame.shape[1]*scale)\n",
    "    \n",
    "    #return the scaled frame\n",
    "    return cv.resize(frame, (width, height), interpolation=cv.INTER_AREA) # performs rescaling by interpolation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 2:__ Create a read_video function that takes a video source(either a video file or a camera index), a scale factor as input and displays a scaled video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_video(source, scale, side_by_side=False):\n",
    "    try:\n",
    "        capture = cv.VideoCapture(source)\n",
    "        while True:\n",
    "            isTrue, frame = capture.read()\n",
    "            scaled_frame = scale_frame(frame, scale)  # calls the scale_frame function to scale each frame \n",
    "            \n",
    "            cv.imshow('scaled video', scaled_frame)\n",
    "            if side_by_side:\n",
    "                cv.imshow('original video', frame)\n",
    "            \n",
    "            if cv.waitKey(20) & 0XFF == ord('d'):\n",
    "                break\n",
    "        capture.release()\n",
    "    except:\n",
    "        print('error')\n",
    "    finally:\n",
    "        cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 3:__ Verify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_video(source=0, scale=2, side_by_side=True) # calling read_video with live feed, scaling 2X and playing with original by side."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Output__ <br>\n",
    "\n",
    "![](figs/fig4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Playing with various capture attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic Capture parameters:\n",
    "\n",
    "| id |  Parameter | meaning |\n",
    "|---|---|---|\n",
    "| 3 | CAP_PROP_FRAME_WIDTH | width |\n",
    "| 4 | CAP_PROP_FRAME_HEIGHT | Height |\n",
    "| 5 | CAP_PROP_FPS | FPS |\n",
    "| 6 | CAP_PROP_POS_MSEC | Current position of the capture pointer |\n",
    "| 7 | CAP_PROP_FRAME_COUNT | total number of frames in the video file|\n",
    "| 8 | CAP_PROP_BRIGHTNESS | It only works with a camera or webcam. Used to find out the brightness | \n",
    "| 9 | CAP_PROP_CONTRAST | This property also works with the camera or webcam only. Used to find out the contrast on images captured |\n",
    "| 10 | CAP_PROP_SATURATION | This is used to get the saturation of live frames capturing via cameras. This also doesn’t work on the video file.|\n",
    "|11 | CAP_PROP_HUE | This is for knowing the HUE value of the image. Only for cameras.|\n",
    "|12 | CAP_PROP_GAIN | This property is used to get the gain of the image. Wouldn’t work with the video file, simply return “0” if applied on a video file|\n",
    "|13| CAP_PROP_CONVERT_RGB | This property returns a Boolean value which indicates whether the images should be converted to RGB colorspace or not | \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1 Getting the params\n",
    "\n",
    "The following code will read the basic OpenCV parameter from a live video and shows it while streaming from the source. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "def show_details(capture):   # prints the basic attributes \n",
    "    clear_output(wait=True)  # clear the notebook cell after printing \n",
    "    print(f\"CAP_PROP_FRAME_WIDTH \\t: {capture.get(cv.CAP_PROP_FRAME_WIDTH)}\")\n",
    "    print(f\"CAP_PROP_FRAME_HEIGHT \\t: {capture.get(cv.CAP_PROP_FRAME_HEIGHT)}\")\n",
    "    print(f\"CAP_PROP_FPS        \\t: {capture.get(cv.CAP_PROP_FPS)}\")\n",
    "    print(f\"CAP_PROP_POS_MSEC   \\t: {capture.get(cv.CAP_PROP_POS_MSEC)}\")\n",
    "    print(f\"CAP_PROP_FRAME_COUNT \\t: {capture.get(cv.CAP_PROP_FRAME_COUNT)}\")\n",
    "    print(f\"CAP_PROP_BRIGHTNESS \\t: {capture.get(cv.CAP_PROP_BRIGHTNESS)}\")\n",
    "    print(f\"CAP_PROP_CONTRAST   \\t: {capture.get(cv.CAP_PROP_CONTRAST)}\")\n",
    "    print(f\"CAP_PROP_SATURATION \\t: {capture.get(cv.CAP_PROP_SATURATION)}\")\n",
    "    print(f\"CAP_PROP_HUE        \\t: {capture.get(cv.CAP_PROP_HUE)}\")\n",
    "    print(f\"CAP_PROP_GAIN       \\t: {capture.get(cv.CAP_PROP_GAIN)}\")\n",
    "    print(f\"CAP_PROP_CONVERT_RGB \\t: {capture.get(cv.CAP_PROP_CONVERT_RGB)}\")\n",
    "\n",
    "def show_video(source): \n",
    "    capture = cv.VideoCapture(source)\n",
    "    while True:\n",
    "        isTrue, frame = capture.read()\n",
    "        show_details(capture)   # calling the capture details \n",
    "        cv.imshow('Window', frame)\n",
    "        if cv.waitKey(20) & 0xFF == ord('d'): # press 'd' to exit\n",
    "            break\n",
    "    capture.release()\n",
    "    cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CAP_PROP_FRAME_WIDTH \t: 640.0\n",
      "CAP_PROP_FRAME_HEIGHT \t: 480.0\n",
      "CAP_PROP_FPS        \t: 30.0\n",
      "CAP_PROP_POS_MSEC   \t: 736991915.211\n",
      "CAP_PROP_FRAME_COUNT \t: -1.0\n",
      "CAP_PROP_BRIGHTNESS \t: 0.0\n",
      "CAP_PROP_CONTRAST   \t: 0.0\n",
      "CAP_PROP_SATURATION \t: 64.0\n",
      "CAP_PROP_HUE        \t: 0.0\n",
      "CAP_PROP_GAIN       \t: 1.0\n",
      "CAP_PROP_CONVERT_RGB \t: 1.0\n"
     ]
    }
   ],
   "source": [
    "show_video(source=0) # calling the live capture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2. Setting the params "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## set params\n",
    "alter_param = {\n",
    "    'width' : 640, \n",
    "    'height': 480, \n",
    "    'fps' : 30, \n",
    "    'brightness' : 50,\n",
    "    'contrast' : 10,\n",
    "    'saturation' : 100,\n",
    "    'hue': 0,\n",
    "    'gain' : 1,\n",
    "    'rgb' : 1 \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sourcecode\n",
    "from IPython.display import clear_output\n",
    "\n",
    "def show_details(capture):   # prints the basic attributes \n",
    "    clear_output(wait=True)  # clear the notebook cell after printing \n",
    "    print(f\"CAP_PROP_FRAME_WIDTH \\t: {capture.get(cv.CAP_PROP_FRAME_WIDTH)}\")\n",
    "    print(f\"CAP_PROP_FRAME_HEIGHT \\t: {capture.get(cv.CAP_PROP_FRAME_HEIGHT)}\")\n",
    "    print(f\"CAP_PROP_FPS        \\t: {capture.get(cv.CAP_PROP_FPS)}\")\n",
    "    print(f\"CAP_PROP_POS_MSEC   \\t: {capture.get(cv.CAP_PROP_POS_MSEC)}\")\n",
    "    print(f\"CAP_PROP_FRAME_COUNT \\t: {capture.get(cv.CAP_PROP_FRAME_COUNT)}\")\n",
    "    print(f\"CAP_PROP_BRIGHTNESS \\t: {capture.get(cv.CAP_PROP_BRIGHTNESS)}\")\n",
    "    print(f\"CAP_PROP_CONTRAST   \\t: {capture.get(cv.CAP_PROP_CONTRAST)}\")\n",
    "    print(f\"CAP_PROP_SATURATION \\t: {capture.get(cv.CAP_PROP_SATURATION)}\")\n",
    "    print(f\"CAP_PROP_HUE        \\t: {capture.get(cv.CAP_PROP_HUE)}\")\n",
    "    print(f\"CAP_PROP_GAIN       \\t: {capture.get(cv.CAP_PROP_GAIN)}\")\n",
    "    print(f\"CAP_PROP_CONVERT_RGB \\t: {capture.get(cv.CAP_PROP_CONVERT_RGB)}\")\n",
    "\n",
    "def alter_params(capture, alter_param):   # alters the parameters \n",
    "    capture.set(cv.CAP_PROP_FRAME_WIDTH, alter_param['width'])\n",
    "    capture.set(cv.CAP_PROP_FRAME_HEIGHT, alter_param['height'])\n",
    "    capture.set(cv.CAP_PROP_FPS, alter_param['fps'])\n",
    "    capture.set(cv.CAP_PROP_BRIGHTNESS, alter_param['brightness'])\n",
    "    capture.set(cv.CAP_PROP_CONTRAST, alter_param['contrast'])\n",
    "    capture.set(cv.CAP_PROP_SATURATION, alter_param['saturation'])\n",
    "    capture.set(cv.CAP_PROP_HUE, alter_param['hue'])\n",
    "    capture.set(cv.CAP_PROP_GAIN, alter_param['gain'])\n",
    "    capture.set(cv.CAP_PROP_CONVERT_RGB, alter_param['rgb'])\n",
    "    return capture\n",
    "\n",
    "def show_video(source):    # renders the video stream \n",
    "    print('Preparing capture... ')\n",
    "    try:\n",
    "        capture = cv.VideoCapture(source)\n",
    "        capture = alter_params(capture, alter_param) # calling to alter the params\n",
    "        print('Displaying... ')\n",
    "        while True:\n",
    "            isTrue, frame = capture.read()\n",
    "            show_details(capture)   # calling the capture details \n",
    "            cv.imshow('Window', frame)\n",
    "            if cv.waitKey(20) & 0xFF == ord('d'): # press 'd' to exit\n",
    "                break\n",
    "        capture.release()\n",
    "    except:\n",
    "        print('Error')\n",
    "    finally:\n",
    "        cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CAP_PROP_FRAME_WIDTH \t: 640.0\n",
      "CAP_PROP_FRAME_HEIGHT \t: 480.0\n",
      "CAP_PROP_FPS        \t: 30.0\n",
      "CAP_PROP_POS_MSEC   \t: 744583848.9555\n",
      "CAP_PROP_FRAME_COUNT \t: -1.0\n",
      "CAP_PROP_BRIGHTNESS \t: 0.0\n",
      "CAP_PROP_CONTRAST   \t: 0.0\n",
      "CAP_PROP_SATURATION \t: 64.0\n",
      "CAP_PROP_HUE        \t: 0.0\n",
      "CAP_PROP_GAIN       \t: 1.0\n",
      "CAP_PROP_CONVERT_RGB \t: 1.0\n"
     ]
    }
   ],
   "source": [
    "show_video(source=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__output__ <br>\n",
    "\n",
    "![](figs/fig5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3: Drawing shapes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first practice, we're going to see how to create a blank (dummy) image using __numpy__ and then draw basic shapes on top of it. Then we'll do the same on a real image and finally on a video.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Drawing on a blank image "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Creating a black image \n",
    "\n",
    "As digital images are read as a $m\\times n$ matrix, we do a reverse engineering here. We'll first create a blank matrix and present it as an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np   # library to to matrix operations\n",
    "import cv2 as cv\n",
    "\n",
    "image_size = (640,480)  # define the image size\n",
    "\n",
    "blank_matrix = np.zeros(image_size, dtype='uint8') # create a 8-bit unsigned integer matrix \n",
    "try:\n",
    "    cv.imshow(winname='blank_image', mat=blank_matrix)\n",
    "    cv.waitKey(0)\n",
    "except:\n",
    "    print('Error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create a color image, we need a 3D matrix. the first two dimension are the height and width and the third one is the color depth.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = (640,480,3)  # define the image size with color depth of 3 channel\n",
    "\n",
    "blank_matrix = np.zeros(image_size, dtype='uint8') # create a 8-bit unsigned integer matrix \n",
    "blank_matrix[:] = 0,255,0   # the values are in R,G,B format (change it to get more colors)\n",
    "try:\n",
    "    cv.imshow(winname='blank_image', mat=blank_matrix)\n",
    "    cv.waitKey(0)\n",
    "except:\n",
    "    print('Error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also color the image partially, by selecting specific row and column range "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = (640,480,3)  # define the image size with color depth of 3 channel\n",
    "\n",
    "height, width, depth = image_size\n",
    "\n",
    "blank_matrix = np.zeros(image_size, dtype='uint8') # create a 8-bit unsigned integer matrix \n",
    "\n",
    "# coloring image segments\n",
    "blank_matrix[0 : height//2 , 0 : width//2] = 255,0,0   # top left quarter \n",
    "blank_matrix[0 : height//2 , width//2 : width] = 0,255,0   # top right quarter \n",
    "blank_matrix[height//2 : height , 0 : width//2] = 0,0,255   # bottom left quarter\n",
    "blank_matrix[height//2 : height , width//2 : width] = 255,0,255   # bottom left quarter  \n",
    "\n",
    "try:\n",
    "    cv.imshow(winname='blank_image', mat=blank_matrix)\n",
    "    cv.waitKey(0)\n",
    "except:\n",
    "    print('Error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Creating basic shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = (600,800,3)  # define the image size\n",
    "\n",
    "blank_matrix = np.zeros(image_size, dtype='uint8') # create a 8-bit unsigned integer matrix \n",
    "\n",
    "# adding text \n",
    "cv.putText(img=blank_matrix, \n",
    "           org=(300, 50),         # origin point \n",
    "           text='Test Shapes',    # text to print \n",
    "           color=(255,255,0),     # Text color\n",
    "           fontFace=cv.FONT_HERSHEY_PLAIN, # font to use\n",
    "           fontScale=2)           # font size      \n",
    "\n",
    "#drawing a rectangle\n",
    "cv.rectangle(img=blank_matrix,     # where to draw?\n",
    "            pt1=(100,100),         # top-left \n",
    "            pt2=(300,300),         # bottom-right\n",
    "            color=(255,0,0),       # stroke-color\n",
    "            thickness=2)           # stroke-width\n",
    "\n",
    "#drawing a rectangle with filled color\n",
    "cv.rectangle(img=blank_matrix,     \n",
    "            pt1=(200,200),         \n",
    "            pt2=(400,400),       \n",
    "            color=(255,0,0),       \n",
    "            thickness=-1)   # stroke-width (use cv.FILLED or -1 to fill)\n",
    "\n",
    "#drawing a circle\n",
    "cv.circle(img=blank_matrix, \n",
    "          center=(400,400),        # cordinate of the center \n",
    "          radius=200,              # radius \n",
    "          color=(0,255,0),         \n",
    "          thickness=2)\n",
    "\n",
    "#drawing a line \n",
    "cv.line(img=blank_matrix,\n",
    "        pt1=(100,100),       # start coordinate \n",
    "        pt2=(400,400),       # end coordinate  \n",
    "        color=(0,0,255), \n",
    "        thickness=2)\n",
    "\n",
    "try:\n",
    "    cv.imshow(winname='blank_image', mat=blank_matrix)\n",
    "    cv.waitKey(0)\n",
    "except:\n",
    "    print('Error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](figs/shapes_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task \n",
    "Write a function to draw the figure below <br>\n",
    "![](figs/shapes.png) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0f3bb31c5957d94de20b221c63d8001d2e67169bbb608e5802db09df6465f3be"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
