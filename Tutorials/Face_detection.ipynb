{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face detection \n",
    "\n",
    "_The face detection algorithms detects facial pattern through varios classifiers in an image to detect if there is a face in it_. In this tutorial, we shall see the following most popular algorithms on Face Detaction and apply them through python.\n",
    "1. __Haarcascade Classifier__: This the most simple face ddetection algorithm for detecting Face and Eyes. This classifier along with detecting faces, can also detect other objects like a human body or cars. \n",
    "2. __Histogram of Oriented Gradient (HOG)__: HOG is more effiecient that Haarcascade. \n",
    "3. __Convolutional Neural Network (CNN)__: CNN is aguably the most robust algorithm for face and object detection.   \n",
    "\n",
    "In the implementation, we shall use OpenCV for the Haarcascade classifier and Dlib library for HOG and CNN. Note that, we're not going to build the classifier in this Lab, rather we shall see how to leverage existinig classifiers for detecting objects. Building classifiers fall  under the discussion of Feature Training which will be covered during upcoming sections of this course."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## brief of Haarcasde classifier\n",
    "\n",
    "* Every image is comprised by a grid of pixels. The shape of the grid in $m\\times n$ called the resolution and the number of bits represent each pixel is called the bit-depth or color-depth. \n",
    "* In face detection it is a common practice to convert a color image into a grey-scale image; because, a greay scale image reduces the image size by 67% having preserved all the patterns for detection. \n",
    "* Steps\n",
    "    1. The classifier is trained with two sets of objects one with faces and the other expect face. \n",
    "    2. The training samples then gets fed into AdaBoost training algorithm for computing the classifiers by the facial features.\n",
    "    3. An passes through all the classifiers, if all the features are detected then Haarcaascade detects a face in it. The number of features passed determines the confifence value. If the confidence value does not exceed a cirtain theshold, the algorithm does not detect an face. \n",
    "    4. The classifier segments an image into multiple sub-areas and applies step 3 on each segment. When a Face is found at any segment the location of the segment is returned.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv    #import the openCV library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 1__: Load an image from local directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = cv.imread('images/people2.jpg')    # read the image \n",
    "cv.imshow(winname='original', mat=image)   # show the image \n",
    "cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](figs/fd_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First lets see the image resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resolution is 600 X 800 with 3 color channels\n"
     ]
    }
   ],
   "source": [
    "height, width, depth = image.shape\n",
    "print(f'Resolution is {height} X {width} with {depth} color channels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 2__: downscale the image for larger image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scale_factor = 0.75     # set the scale factor \n",
    "if scale_factor == 1:\n",
    "    image_scalled = image\n",
    "else:\n",
    "    image_scalled = cv.resize(image,                                                   # source image \n",
    "                            (int(width * scale_factor), int(height * scale_factor)),  # target resolution \n",
    "                            interpolation=cv.INTER_AREA)                              # interpolation used\n",
    "cv.imshow(winname='Scalled', mat=image_scalled)   # show the image \n",
    "cv.waitKey(0)                     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](figs/fd2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 3:__  Convert the image into a Greayscale image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resolution is 450 X 600\n"
     ]
    }
   ],
   "source": [
    "image_grey = cv.cvtColor(image_scalled,cv.COLOR_BGR2GRAY)      # converting into a grey scale\n",
    "cv.imshow(winname='Greyscaled', mat=image_grey)   # show the image \n",
    "cv.waitKey(0)   \n",
    "\n",
    "#print the image resolution   \n",
    "height, width = image_grey.shape\n",
    "print(f'Resolution is {height} X {width}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](figs/fd_3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 4:__ Creatinig a face detector and detect faces\n",
    "The pretained classifiers can be found at : https://github.com/opencv/opencv/tree/master/data/haarcascades. The files are located locally in the `classifier/haarcascade` folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 4.1. Load the classifier \n",
    "face_detector = cv.CascadeClassifier(cv.data.haarcascades + \"haarcascade_frontalface_default.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[231 275 150 150]\n",
      " [158 174 119 119]\n",
      " [330  35 118 118]\n",
      " [ 41 150 151 151]\n",
      " [222  54 121 121]\n",
      " [349 257 180 180]]\n"
     ]
    }
   ],
   "source": [
    "# 4.2. Detect faces \n",
    "face_detected = face_detector.detectMultiScale(image_grey, \n",
    "                                              scaleFactor = 1.1, # scale according to the face size (>=1) \n",
    "                                              minNeighbors = 5,  # reduces False positives \n",
    "                                              minSize = (10,10)) # min size of a face to be detected\n",
    "                                               \n",
    "print(face_detected)   # returns a list of [x, y, width, height] of the detected area "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 5:__ Draw reactangle around the face "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = None\n",
    "temp = image_scalled.copy()   # duplicate the image\n",
    "for x,y,w,h in face_detected:\n",
    "    # determine point1 and point2\n",
    "    top_left = (x,y)\n",
    "    bottom_right = (x+h, y+w)\n",
    "    image_marked = cv.rectangle(temp, pt1=top_left, pt2=bottom_right, color=(0,255,0),thickness=2) #draw rect\n",
    "\n",
    "cv.imshow('Face_detected', image_marked)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](figs/fd_4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Detection from a video "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "def face_detect(frame):\n",
    "    '''\n",
    "    Input : Frame \n",
    "    output: Frame with face detected \n",
    "    '''\n",
    "    frame_gr = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "    face_detector = cv.CascadeClassifier(cv.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "    face_detected = face_detector.detectMultiScale(frame_gr)\n",
    "    number_of_faces = len(face_detected.tolist())\n",
    "    count = number_of_faces\n",
    "    if count:\n",
    "        for x,y,w,h in face_detected:\n",
    "            cv.rectangle(img=frame, pt1=(x,y), pt2=(x+h,y+h), color=(255,0,255),thickness=2)\n",
    "            cv.putText(img=frame,text=f'Face {count}', org=(x,y),fontFace=cv.FONT_HERSHEY_PLAIN, fontScale=1, color=(0,0,255))\n",
    "            count-=1\n",
    "    \n",
    "    cv.putText(img=frame,text=f'Face Count = {number_of_faces}', org=(100,100),fontFace=cv.FONT_HERSHEY_PLAIN, fontScale=2, color=(0,0,255))\n",
    "    return frame\n",
    "\n",
    "def read_video(file):\n",
    "    capture = cv.VideoCapture(file)\n",
    "    while True:\n",
    "        isTrue, frame = capture.read()\n",
    "        frame_org = frame.copy()\n",
    "        frame_marked = face_detect(frame)\n",
    "        cv.imshow(winname='Original', mat=frame_org)\n",
    "        cv.imshow(winname='Face Detected', mat=frame_marked)\n",
    "        if cv.waitKey(20) & 0xFF == ord('d'):        # stop the video is the key 'd' is pressed (you can change as per your choice)\n",
    "            break\n",
    "    capture.release()  \n",
    "    cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'tolist'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19604\\600780394.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mread_video\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'videos\\sample_vid3.mp4'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19604\\4262598464.py\u001b[0m in \u001b[0;36mread_video\u001b[1;34m(file)\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[0misTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcapture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[0mframe_org\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mframe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m         \u001b[0mframe_marked\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mface_detect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m         \u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwinname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Original'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mframe_org\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwinname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Face Detected'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mframe_marked\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19604\\4262598464.py\u001b[0m in \u001b[0;36mface_detect\u001b[1;34m(frame)\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mface_detector\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCascadeClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhaarcascades\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"haarcascade_frontalface_default.xml\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mface_detected\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mface_detector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetectMultiScale\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe_gr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mnumber_of_faces\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mface_detected\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[0mcount\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumber_of_faces\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcount\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'tolist'"
     ]
    }
   ],
   "source": [
    "read_video(file='videos\\sample_vid3.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "68aba9d269748a66a81cf2fb1202c87b1de056993fe70c4fea8f276412ef4f9d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
