{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face detection \n",
    "\n",
    "_The face detection algorithms detects facial pattern through varios classifiers in an image to detect if there is a face in it_. In this tutorial, we shall see the following most popular algorithms on Face Detaction and apply them through python.\n",
    "1. __Haarcascade Classifier__: This the most simple face ddetection algorithm for detecting Face and Eyes. This classifier along with detecting faces, can also detect other objects like a human body or cars. \n",
    "2. __Histogram of Oriented Gradient (HOG)__: HOG is more effiecient that Haarcascade. \n",
    "3. __Convolutional Neural Network (CNN)__: CNN is aguably the most robust algorithm for face and object detection.   \n",
    "\n",
    "In the implementation, we shall use OpenCV for the Haarcascade classifier and Dlib library for HOG and CNN. Note that, we're not going to build the classifier in this Lab, rather we shall see how to leverage existinig classifiers for detecting objects. Building classifiers fall  under the discussion of Feature Training which will be covered during upcoming sections of this course."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1: HaarCascade Classifier "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Brief of Haarcasde classifier\n",
    "\n",
    "* Every image is comprised by a grid of pixels. The shape of the grid in $m\\times n$ called the resolution and the number of bits represent each pixel is called the bit-depth or color-depth. \n",
    "* In face detection it is a common practice to convert a color image into a grey-scale image; because, a greay scale image reduces the image size by 67% having preserved all the patterns for detection. \n",
    "* Steps\n",
    "    1. The classifier is trained with two sets of objects one with faces and the other expect face. \n",
    "    2. The training samples then gets fed into AdaBoost training algorithm for computing the classifiers by the facial features.\n",
    "    3. An passes through all the classifiers, if all the features are detected then Haarcaascade detects a face in it. The number of features passed determines the confifence value. If the confidence value does not exceed a cirtain theshold, the algorithm does not detect an face. \n",
    "    4. The classifier segments an image into multiple sub-areas and applies step 3 on each segment. When a Face is found at any segment the location of the segment is returned.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv    #import the openCV library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 1__: Load an image from local directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv.imread('images/people2.jpg')    # read the image \n",
    "# cv.imshow(winname='original', mat=image)   # show the image \n",
    "# cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](figs/fd_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First lets see the image resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resolution is 600 X 800 with 3 color channels\n"
     ]
    }
   ],
   "source": [
    "height, width, depth = image.shape\n",
    "print(f'Resolution is {height} X {width} with {depth} color channels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 2__: downscale the image for larger image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scale_factor = 0.75     # set the scale factor \n",
    "if scale_factor == 1:\n",
    "    image_scalled = image\n",
    "else:\n",
    "    image_scalled = cv.resize(image,                                                   # source image \n",
    "                            (int(width * scale_factor), int(height * scale_factor)),  # target resolution \n",
    "                            interpolation=cv.INTER_AREA)                              # interpolation used\n",
    "cv.imshow(winname='Scalled', mat=image_scalled)   # show the image \n",
    "cv.waitKey(0)                     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](figs/fd2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 3:__  Convert the image into a Greayscale image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resolution is 450 X 600\n"
     ]
    }
   ],
   "source": [
    "image_grey = cv.cvtColor(image_scalled,cv.COLOR_BGR2GRAY)      # converting into a grey scale\n",
    "cv.imshow(winname='Greyscaled', mat=image_grey)   # show the image \n",
    "cv.waitKey(0)   \n",
    "\n",
    "#print the image resolution   \n",
    "height, width = image_grey.shape\n",
    "print(f'Resolution is {height} X {width}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](figs/fd_3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 4:__ Creatinig a face detector and detect faces\n",
    "The pretained classifiers can be found at : https://github.com/opencv/opencv/tree/master/data/haarcascades. The files are located locally in the `classifier/haarcascade` folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 4.1. Load the classifier \n",
    "face_detector = cv.CascadeClassifier(cv.data.haarcascades + \"haarcascade_frontalface_default.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[231 275 150 150]\n",
      " [158 174 119 119]\n",
      " [330  35 118 118]\n",
      " [ 41 150 151 151]\n",
      " [222  54 121 121]\n",
      " [349 257 180 180]]\n"
     ]
    }
   ],
   "source": [
    "# 4.2. Detect faces \n",
    "face_detected = face_detector.detectMultiScale(image_grey, \n",
    "                                              scaleFactor = 1.1, # scale according to the face size (>=1) \n",
    "                                              minNeighbors = 5,  # reduces False positives \n",
    "                                              minSize = (10,10)) # min size of a face to be detected\n",
    "                                               \n",
    "print(face_detected)   # returns a list of [x, y, width, height] of the detected area "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 5:__ Draw reactangle around the face "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = None\n",
    "temp = image_scalled.copy()   # duplicate the image\n",
    "for x,y,w,h in face_detected:\n",
    "    # determine point1 and point2\n",
    "    top_left = (x,y)\n",
    "    bottom_right = (x+h, y+w)\n",
    "    image_marked = cv.rectangle(temp, pt1=top_left, pt2=bottom_right, color=(0,255,0),thickness=2) #draw rect\n",
    "\n",
    "cv.imshow('Face_detected', image_marked)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](figs/fd_4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.2. Face Detection from a video & Live source "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "def face_detect(frame, scale, face_detector):\n",
    "    '''\n",
    "    Input : Frame \n",
    "    output: Frame with face detected \n",
    "    '''\n",
    "    height, width, channel = frame.shape\n",
    "    if scale == 1:\n",
    "        frame_scalled = frame\n",
    "    else:\n",
    "        frame_scalled = cv.resize(frame,                                                   # source image \n",
    "                                (int(width * scale), int(height * scale)),  # target resolution \n",
    "                                interpolation=cv.INTER_AREA\n",
    "                        )  \n",
    "    frame_gr = cv.cvtColor(frame_scalled, cv.COLOR_BGR2GRAY)\n",
    "    \n",
    "    face_detected = face_detector.detectMultiScale(frame_gr)\n",
    "    number_of_faces = len(face_detected)\n",
    "    count = number_of_faces\n",
    "    if count:\n",
    "        for x,y,w,h in face_detected:\n",
    "            cv.rectangle(img=frame_scalled,\n",
    "                         pt1=(x,y), pt2=(x+h,y+h), \n",
    "                         color=(255,0,255),\n",
    "                         thickness=2)\n",
    "            cv.putText(img=frame_scalled,\n",
    "                       text=f'Face {count}', \n",
    "                       org=(x,y),\n",
    "                       fontFace=cv.FONT_HERSHEY_PLAIN, \n",
    "                       fontScale=1, \n",
    "                       color=(0,255), \n",
    "                       thickness=1)\n",
    "            count-=1\n",
    "    \n",
    "    cv.putText(img=frame_scalled,\n",
    "               text=f'Face Count = {number_of_faces}', \n",
    "               org=(50,50),\n",
    "               fontFace=cv.FONT_HERSHEY_PLAIN,\n",
    "               fontScale=2, \n",
    "               color=(0,255,255), \n",
    "               thickness=2)\n",
    "    return frame_scalled\n",
    "\n",
    "def read_video(src, scale):\n",
    "    capture = cv.VideoCapture(src)\n",
    "    face_detector = cv.CascadeClassifier(cv.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "    while True:\n",
    "        isTrue, frame = capture.read()\n",
    "        frame_org = frame.copy()\n",
    "        frame_marked = face_detect(frame, scale, face_detector)\n",
    "        cv.imshow(winname='Original', mat=frame_org)\n",
    "        cv.imshow(winname='Face Detected', mat=frame_marked)\n",
    "        if cv.waitKey(20) & 0xFF == ord('d'):        # stop the video is the key 'd' is pressed (you can change as per your choice)\n",
    "            break\n",
    "    capture.release()  \n",
    "    cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = 1\n",
    "read_video(src=0, scale=scale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](figs/fd_5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2: Face detection using HOG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=2);   # create a plot for the images\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 1:__ Read the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlib      # to install: pip install cmake wheel dlib \n",
    "import cv2 as cv # for reading images\n",
    "\n",
    "image = cv.imread('images/people2.jpg')\n",
    "image_rgb = cv.cvtColor(image, cv.COLOR_BGR2RGB)\n",
    "\n",
    "# cv.imshow(winname='Original', mat=image)\n",
    "# cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](figs/image_org.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 2__: Create a classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_detector = dlib.get_frontal_face_detector()    # create a fronal face detector object "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__STep 3__: Detect Faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Face Positions\n",
      "------------------------------------\n",
      "\t face 0 \t = [(231, 259) (355, 383)]\n",
      "\t face 1 \t = [(313, 393) (492, 572)]\n",
      "\t face 2 \t = [(74, 214) (254, 393)]\n",
      "\t face 3 \t = [(427, 62) (576, 211)]\n",
      "\t face 4 \t = [(314, 107) (438, 231)]\n",
      "\t face 5 \t = [(452, 337) (710, 595)]\n",
      "------------------------------------\n",
      "Number of face dettected = 6\n"
     ]
    }
   ],
   "source": [
    "face_detected = face_detector(image)  # apply face detection on a given image\n",
    "print('Face Positions')\n",
    "print('------------------------------------')\n",
    "for i  in range(len(face_detected)):\n",
    "    print(f'\\t face {i} \\t = {face_detected[i]}')\n",
    "print('------------------------------------')\n",
    "print(f'Number of face dettected = {len(face_detected)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 4__: Mark Faces "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "233"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_marked = image.copy()\n",
    "for face in face_detected:\n",
    "    top_left, bottom_right = (face.left(), face.top()),(face.right(), face.bottom())\n",
    "    cv.rectangle(img=image_marked, pt1=top_left, pt2=bottom_right, color=(0,255,0), thickness=2) # mark faces\n",
    "cv.imshow(winname='Marked', mat=image_marked)\n",
    "cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](figs/image_marked.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2.2. Apply HOG on a live source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlib\n",
    "import cv2 as cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HOG Based Face detection\n",
    "\n",
    "def hog_detection(frame, classfier):\n",
    "    hog_face_detector = classfier\n",
    "    face_detected = hog_face_detector(frame)\n",
    "\n",
    "    face_count = len(face_detected)\n",
    "\n",
    "    ## face count\n",
    "    cv.putText(img=frame,\n",
    "               text=f'Face Count = {face_count}',\n",
    "               color=(0,255,255),\n",
    "               org=(50,50),fontFace=cv.FONT_HERSHEY_PLAIN,\n",
    "               thickness=2, \n",
    "               fontScale=2\n",
    "               )\n",
    "\n",
    "    for face in face_detected:\n",
    "        t,b,l,r=  face.top(), face.bottom(), face.left(), face.right()\n",
    "        \n",
    "        #mark face\n",
    "        cv.rectangle(img=frame, \n",
    "                     pt1=(l,t), pt2=(r,b), \n",
    "                     color=(0,255,0), thickness=2) \n",
    "        ## Face label \n",
    "        cv.putText(img=frame,\n",
    "                    text=f'Face {face_count}',\n",
    "                    color=(255,0,255),\n",
    "                    org=(l,t-10),fontFace=cv.FONT_HERSHEY_PLAIN, \n",
    "                    thickness=2,\n",
    "                    fontScale=1\n",
    "                    )\n",
    "        face_count -= 1\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_video(src, scale):\n",
    "    capture = cv.VideoCapture(src)\n",
    "    face_detector = dlib.get_frontal_face_detector()\n",
    "    while True:\n",
    "        isTrue, frame = capture.read()\n",
    "        frame_org = frame.copy()\n",
    "        frame_marked = hog_detection(frame, face_detector)\n",
    "        cv.imshow(winname='Original', mat=frame_org)\n",
    "        cv.imshow(winname='Face Detected', mat=frame_marked)\n",
    "        if cv.waitKey(20) & 0xFF == ord('d'):        # stop the video is the key 'd' is pressed (you can change as per your choice)\n",
    "            break\n",
    "    capture.release()  \n",
    "    cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "src=0\n",
    "scale=1\n",
    "read_video(src,scale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](figs/hog_face_detected.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task3: Facial point detection \n",
    "\n",
    "You will need the dataset from here: https://pyimagesearch.com/2017/04/03/facial-landmarks-dlib-opencv-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlib\n",
    "import cv2 as cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "233"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = cv.imread('images/people2.jpg')             # step1: Read image \n",
    "\n",
    "face_detector = dlib.get_frontal_face_detector()    # step2: create face detector objecct\n",
    "face_detected = face_detector(image)                # step3: detect faces \n",
    "\n",
    "point_detector = dlib.shape_predictor('Classifiers/68_FPLM/shape_predictor_68_face_landmarks.dat') # step4: load the 68 Facial point lnadmark dataset\n",
    "\n",
    "# step5: mark faces\n",
    "image_marked = image.copy()       # create a temp. replica  \n",
    "face_count = len(face_detected)\n",
    "for face in face_detected:\n",
    "    t,b,l,r = face.top(), face.bottom(), face.left(), face.right()\n",
    "    cv.rectangle(img=image_marked, \n",
    "                     pt1=(l,t), pt2=(r,b), \n",
    "                     color=(0,255,0), thickness=2) \n",
    "\n",
    "    # step6: mark landmark\n",
    "    points = point_detector(image, face)       # 68 points for each face\n",
    "    for point in points.parts():\n",
    "        cv.circle(img=image_marked, \n",
    "                  center=(point.x, point.y), radius=2, \n",
    "                  color=(0,0,255), thickness=-1\n",
    "         )  # plot each point \n",
    "\n",
    "\n",
    "\n",
    "cv.imshow(winname='original', mat=image)\n",
    "cv.imshow(winname='Marked', mat=image_marked)\n",
    "cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](figs/fpoint.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3.2: Apply 68 Facial landmarks on live feed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlib\n",
    "import cv2 as cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# HOG Based Face detection + 68 facial point detection\n",
    "\n",
    "def landmark_detection(frame, hog_model, fp_model):\n",
    "    '''\n",
    "    hog_model : hog classifier object\n",
    "    fp_model : 68 facial point predictor object \n",
    "    '''\n",
    "    hog_face_detector = hog_model\n",
    "    point_predictor = fp_model\n",
    "\n",
    "    face_detected = hog_face_detector(frame)\n",
    "\n",
    "    face_count = len(face_detected)\n",
    "\n",
    "    ## face count\n",
    "    cv.putText(img=frame,\n",
    "               text=f'Face Count = {face_count}',\n",
    "               color=(0,255,255),\n",
    "               org=(50,50),fontFace=cv.FONT_HERSHEY_PLAIN,\n",
    "               thickness=2, \n",
    "               fontScale=2\n",
    "               )\n",
    "\n",
    "    for face in face_detected:\n",
    "        t,b,l,r=  face.top(), face.bottom(), face.left(), face.right()\n",
    "        points = fp_model(frame, face)\n",
    "        \n",
    "        #mark face\n",
    "        cv.rectangle(img=frame, \n",
    "                     pt1=(l,t), pt2=(r,b), \n",
    "                     color=(0,255,0), thickness=2) \n",
    "        ## Face label \n",
    "        cv.putText(img=frame,\n",
    "                    text=f'Face {face_count}',\n",
    "                    color=(255,0,255),\n",
    "                    org=(l,t-10),fontFace=cv.FONT_HERSHEY_PLAIN, \n",
    "                    thickness=2,\n",
    "                    fontScale=1\n",
    "                    )\n",
    "        face_count-=1\n",
    "\n",
    "        ## plot points\n",
    "        for point in points.parts():\n",
    "            cv.circle(img=frame, \n",
    "                      center=(point.x, point.y), radius=2, \n",
    "                      color=(0,0,255), thickness=-1)\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_video(src, scale):\n",
    "    print('Initializing Camera...')\n",
    "    capture = cv.VideoCapture(src)  \n",
    "    \n",
    "    print('Loading HOG Face detection model...')\n",
    "    face_detector = dlib.get_frontal_face_detector()     # create hog object \n",
    "    \n",
    "    print('Loading 68 Facial Landmark model...')\n",
    "    point_predictor = dlib.shape_predictor('Classifiers/68_FPLM/shape_predictor_68_face_landmarks.dat') # create fp object \n",
    "    \n",
    "    print('Rendering...')\n",
    "    while True:\n",
    "        isTrue, frame = capture.read()\n",
    "        frame_org = frame.copy()\n",
    "        frame_marked = landmark_detection(frame, hog_model=face_detector, fp_model=point_predictor)\n",
    "        cv.imshow(winname='Original', mat=frame_org)\n",
    "        cv.imshow(winname='Face Detected', mat=frame_marked)\n",
    "        if cv.waitKey(20) & 0xFF == ord('d'):        # stop the video is the key 'd' is pressed (you can change as per your choice)\n",
    "            break\n",
    "    capture.release()  \n",
    "    cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Camera...\n",
      "Loading HOG Face detection model...\n",
      "Loading 68 Facial Landmark model...\n",
      "Rendering...\n"
     ]
    }
   ],
   "source": [
    "src=0                 #select source \n",
    "scale=1               #select scale\n",
    "read_video(src,scale) # run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](figs/face_points.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "68aba9d269748a66a81cf2fb1202c87b1de056993fe70c4fea8f276412ef4f9d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
